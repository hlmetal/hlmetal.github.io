---
layout: post
title:  "Mysql知识盘点"
date:   2019-09-11 09:00:30 +0200
categories: mysql
---

Mysql数据库重点知识盘点, 包括高可用架构、索引、事务、锁、引擎等

## 高可用架构
### 双机主备
  <img src= "/assets/files/mysql双机主备.jpg" alt="加载错误" title="mysql双机主备"/>

* 优点: 操作简单, 机器故障自动切换
* 切断: 同时只有一个库工作, 读写压力大, 没有读写分离, 存在并发限制

### 一主一从
类似于双机主备, 但从库支持读, 不仅仅是数据备份
* 优点: 从库支持读, 分担了主库压力, 提升了并发度。一个机器故障了可以自动切换, 操作比较简单
* 缺点: 一台从库,并发支持还不够, 并且一共两台机器, 还存在同时故障的机率, 不够高可用

### 一主多从
  <img src= "/assets/files/mysql一主多从.jpg" alt="加载错误" title="mysql一主多从"/>

* 优点: 多个从库支持读, 分担了主库压力, 明显提升了读并发度
* 缺点: 只有一台主机写, 因此写并发度不高

### MariaDB同步多主机
有代理层实现负载均衡, 多个数据库可以同时进行读写操作;各个数据库之间可以通过Galera Replication方法进行数据同步,每个库理论上数据是完全一致的
  <img src= "/assets/files/mysqlMariaDB同步多主机.jpg" alt="加载错误" title="mysqlMariaDB同步多主机"/>

* 优点: 读写并发度都明显提升, 可以任意节点读写, 可以自动剔除故障节点, 具有较高可靠性
* 缺点: 数据量不支持特别大, 要避免大事务卡死, 如果集群节点一个变慢,其他节点也会跟着变慢

### 数据库中间件
  <img src= "/assets/files/mysql数据库中间件.jpg" alt="加载错误" title="mysql数据库中间件"/>

* mycat分片存储, 每个分片配置一主多从集群
* 优点: 解决高并发高数据量的高可用方案
* 缺点: 维护成本比较大

## 读写分离场景下如何保证读到最新数据
在高并发或网络不佳景的场景下, 如果存在较大主从延迟, 这时候读请求去读从库,就会读到旧数据.最简单暴力的方法, 就是强制读主库.实际上可以使用**缓存标记法**
  <img src= "/assets/files/数据库主从延迟之缓存标记法.jpg" alt="加载错误" title="数据库主从延迟之缓存标记法"/>

1. 写请求更新主库数据, 并在缓存中设置一个标记,表示数据已更新
2. 设置过期时间(估值为主从延迟时间)
3. 读请求过来时, 先判断在缓存中有没有更新标记.如果存在标记,走主库; 反之走从库



## Mysql索引使用注意事项
正确使用索引能够加快查询速率, 但不当使用索引反而会降低性能
### 索引类型
1. 主键索引, 数据列不允许重复, 不允许为NULL, 一个只有一个主键
2. 唯一索引, 数据列不允许重复, 允许NULL, 一个表允许多列创建唯一索引
3. 普通索引, 没有唯一性限制, 允许NULL
4. 全文索引
5. 覆盖索引, 查询列被索引覆盖, 不必读取数据行
6. 组合索引, 多列组成一个索引

### 创建索引原则
1. 最左前缀原则
2. 频繁查询字段使用索引
3. 频繁更新字段不适用
4. 索引列不参与计算
5. 优先考虑扩展索引, 而不是新建
6. order by, group by子句中要注意索引顺序
7. 区分度低字段不适用
8. 定义有外键的数据列一定要建立索引
9. 对text、image类型不适用
10. 删除不再使用或很少使用的索引

### 创建索引方式
1. CREATE TABLE KEY index_name(column);
2. CREATE INDEX index_name ON table_name(column);
3. ALTER TABLE table_name ADD INDEX index_name(column);

### 索引失效情况 
1. 索引列上进行函数运算时, (mysql 8增加函数索引解决)
2. 组合索引中, 不符合最左匹配规则
3. 使用not, !=时
4. 使用like %xxx匹配后缀时, 不符合最左匹配规则, 但xxx%走索引
5. or语句前后没有同时使用索引时
6. 存在隐式转换时, 例如 字符串没有加引号, mysql会自动转换, 此时索引失效
7. 多表连接查询时, 连接顺序也会影响索引的使用

### 索引实现原理(为什么使用B+树, 而不使用二叉树)
1. 哈希表(适合只有等值查询场景)、有序数组(适合范围查询, 不适合插入)、B/B+数(大多数数据库引擎都是使用B树或B+树实现索引存储)
* 因为B树作为一种多路平衡树, 在存储大量数据时, 其高度会比二叉树更低, 这意味这更少的IO次数, 更高的性能
* 实际上数据库数据存储在磁盘上, 而磁盘IO效率比较低, 在随机磁盘IO时会更低, 而树的高度决定IO次数
2. Innodb原则B+数据作为索引存储结构,**B+树中所有非叶子节点存储索引, 叶子节点存储数据**, 叶子节点的数据又通过双向链表关联, 相较于B树有以下优化:
* **B+树中非叶子节点不存储数据, 因此每一层存储的索引数量增加**, 在相同层高的情况下, 会比B树存储更多数据, 使得磁盘IO次数更少
* B+树中叶子节点的数据通过双向链表连接, 在**范围查询**时, 只需要查2个节点后遍历即可, 而B树则要获取所有节点, 因此在范围查询上效率更高
* B+树**全局扫表**时性能更强, 只需要扫所有叶子节点即可, 而B树需要扫描整个树
* 基于这种结构, 使用自增整数作为主键, 可以避免因数据增加带来的叶子节点分裂产生的大量运算问题 

#### 二叉树、自平衡二叉查找树(AVL)、B树
1. 二叉树: 每个节点两个分支, 相对于单向链表,多了一个分支
2. 二叉查找树: 在二叉树基础上, 加入规则: 左子树所有节点的值都小于它的根节点, 右子树所有节点的值都大于它的根节点
3. AVL树: 二叉查找树会出现斜树问题, 因此在二叉查找树基础上, 加入规则: 左右两个子树的高度差绝对值不超过1, 采用左旋、右旋方式实现平衡
4. B树: 多路平衡查找树, 满足AVL树规则的同时, 有多个子树, 子树数量= 关键字数 + 1
5. B+数: B树基础上, 有两点不同: 数据都存在叶子节点, 子树数量 = 关键字数
6. MongoDB使用的是B树，MongoDB中所有的节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询会更快
7. MySQL数据的关联性非常强，区间访问是常见的一种情况，B+树由于数据全部存储在叶子节点，并且通过指针串在一起，这样就很容易的进行区间遍历甚至全部遍历

### 磁盘IO工作原理
磁盘IO的工作原理是，首先系统会把数据逻辑地址传给磁盘，磁盘控制电路按照寻址逻辑把逻辑地址翻译成物理地址，也就是确定要读取的数据在哪个磁道，哪个扇区。
为了读取这个扇区的数据，需要把磁头放在这个扇区的上面，为了实现这一个点，磁盘会不断旋转，把目标扇区旋转到磁头下面，使得磁头找到对应的磁道，这里涉及到寻道事件以及旋转时间

### 索引不适用场景
1. 数据量较少时
2. 数据更新频繁时, 会将降低写入性能, 因为记录数据之外还要更新索引
3. 区分度低的字段, 例如性别

### innodb索引策略
1. 覆盖索引
2. 最左前缀原则
3. 索引下推, 在索引遍历过程中, 对索引中包含的字段优先判断, 直接过滤不符合条件的记录, 减少回表次数

### 聚集索引和非聚集索引
1. 聚集索引即主键索引
2. 非聚集索引即非主键索引, 也叫二级索引
3. 在innodb引擎中, 每张表的数据对应的物理文件本身就是按照B+树来组织的一种索引结构, 而聚集索引就是按照每张表的主键来构建一颗B+树. 聚集索引不仅是一种索引类型, 也是一种数据存储方式, 所以每张表都必须有1个主键,没有设置则hui添加一个隐式列作为主键索引, 每个表只能有个一主键索引, 如果有多个也意味着多份数据副本, 会造成磁盘浪费, 维护困难
4. 基于非主键索引查询一条完整数据记录, 最终还是需要访问主键索引

#### 具体过程
以select * from user where age=32;为例, 其中id为主键索引, age为二级索引
1. 搜索idx_age索引树, 将磁盘块1加载到内存, 由于32<37,搜索左路分支,到磁盘寻址磁盘块2
2. 将磁盘块2加载到内存中, 在内存继续遍历, 找到age=32的记录, 取得id = 100
  <img src= "/assets/files/二级索引树.jpg" alt="加载错误" title="二级索引树"/>
3. 拿到id=100后, 搜索id主键索引树, 将磁盘块1加载内存, 在内存遍历找到100, 但非叶子节点不保存数据, 索引会继续搜索左分支, 到磁盘寻址磁盘块2
4. 将磁盘块2加载内存, 在内存遍历, 找到id=100的记录, 返回R1这行数据
  <img src= "/assets/files/主键索引树.jpg" alt="加载错误" title="主键索引树"/>

## limit 1000000加载慢如何解决
1. 如果id连续递增, 每次查询返回最大id, 然后带上这个where > id的条件再limit
2. 增加分页缓存
3. 若不是必须的业务需求, 不要做这么大的分页, 即限制分页大小

## 如何选择合适的分布式主键方案
1. UUID
2. redis生成ID
3. zookeeper生成的ID
4. MongoDB生成的ObjectId
4. snowflake算法

### 分布式ID特征
1. 全局唯一
2. 单调递增
3. 保证安全, ID需要无规则性
4. 含时间戳, 需要记录系统时间戳
5. 高可用, 发布一个获取分布式ID的请求, 服务器至少要保证99.999%的情况下给创建一个全局唯一的分布式ID
6. 低延迟, 发布一个获取分布式ID的请求, 要快, 急速
7. 高QPS, 假如并发一口气10万个创建分布式ID请求, 服务器要顶得住并且成功创建10万个分布式ID

### 雪花算法
  <img src= "/assets/files/雪花算法.jpg" alt="加载错误" title="雪花算法"/>

* 第1位表示正负数, 一般生成的id都为正数, 默认为0
* 接着的41位位时间戳, 表示自选顶的时期以来的毫秒数
* 然后接着的10位是计算机ID
* 最后12位是每台机器上生成ID的序列号

#### 优缺点
1. 分布式系统内不会产生ID碰撞, 效率高
2. 不需要依赖数据库等第三方系统, 稳定性更高, 可以根据自身业务分配bit位, 非常灵活
3. 生成ID的性能也非常高, 每秒能生成26万个自增可排序的ID
4. 它依赖机器时钟, 如果机器时钟回拨,可能会导致ID重复

## 如何优化SQL
### SQL语句本身优化
1. 查询慢SQL日志, 定位慢SQL
2. 使用explain查询SQL执行计划, 重点关注type,key,rows, filter等字段, 从而定位执行慢的根本原因
3. 使用show profile查看SQL的资源使用详细信息, 可以看到SQL执行时cpu、内存、磁盘等资源的开销情况

### MySQL程序配置优化
1. binlog日志是否开启
2. 缓存池大小
3. 全局配置、会话配置等

### 硬件系统优化
1. CPU、内存的大小、磁盘读写速度、网络带宽等
2. 应用文件句柄数、操作系统网络的配置等

### 架构优化
1. 数据量大, 考虑分库分表, 降低单个服务器节点的IO压力
2. 读多写少, 考虑读写分离, 可以避免读写冲突导致的性能问题
3. 主从集群, 提高服务的可用性
4. 针对热点数据, 引入中间层, 如Redis缓存, MongoDB等

## 分库分表设计
### 方案
1. 水平分库分表: 以字段为依据, 按照一定策略(hash, range, 雪花算法等), 将数据拆分到不同库表
* range: 利于数据迁移, 但存在数据热点问题
* hash: 不会存在明显热点问题, 但不利于扩容


2. 垂直分库分表:
* 垂直分库, 以表为依据, 按照业务归属不同, 拆分到不同库
* 垂直分表, 以字段为依据, 按照字段的活跃性, 将表中字段拆分到不同表

### 常用中间件
1. sharding-jdbc, 基于jdbc驱动接口的扩展, 无需额外的代理
2. mycat, 基于代理, 复写了Mysql协议, 将mycat伪装成mysql数据库
3. TDDL
4. vitess
5. Oceanus
6. Atlas

### 问题
1. 事务问题: 需要分布式事务
2. 数据迁移: 容量规划、扩容等问题
3. 跨节点查询问题
4. ID问题: 数据拆分后, 不能再依赖自增主键
5. 跨分片排序分页问题

### 分表不用停服的方法
1. 编写代理层, 加个开关(控制访问新的DAO还是老的DAO), 灰度期间，还是访问老的DAO
2. 发版全量后, 开启双写, 既在旧表新增和修改,也在新表新增和修改, 日志或者临时表记下新表ID起始值, 旧表中小于这个值的数据就是存量数据, 这批数据就是要迁移的
3. 通过脚本将旧表的存量数据写入新表
4. 停读旧表改读新表, 此时新表已经承载了所有读写业务, 但是这时候不要立刻停写旧表, 需要保持双写一段时间
5. 当读写新表一段时间之后, 如果没有业务问题, 就可以停写旧表

## Innodb和MyISAM的区别
### 数据存储结构不同
1. Innodb在磁盘上的存储, 分为两个文件, 一个存储表结构, 一个存储索引和数据
2. MyISAM在磁盘上的存储, 分为三个文件, 一个存储表结构, 一个存储索引, 一个存储数据, 索引查找时, 叶子节点存储的是数据的磁盘位置, 而不是数据本身

### 数据存储空间不同
1. Innodb需要更多的内存和磁盘,在主内存中会建立缓冲池来高速缓冲索引和数据
2. MyISAM是可以被压缩的, 存储空间较小, 三种存储方式: 静态表、动态表、压缩表

### 事务支持不同
Innodb支持事务, MyISAM不支持
### 锁的支持不同
Innodb支持行锁、表锁等, MyISAM只支持表锁
### 对外键支持不同
Innodb支持外键, MyISAM不支持

## innodb引擎四大特性
1. 插入缓冲
2. 二次写
3. 自适应哈希索引
4. 预读

## 事务隔离级别
事务隔离级别是为了解决多个并行事务竞争时导致数据安全性问题的一种规范, 根据业务需求, 选择不同隔离级别
#### 读未提交, 最低隔离级别, 可能产生脏读、幻读、不可重复读
事务1即使未提交, 事务2仍可以读取到事务1的变更数据
#### 读已提交, 可能产生幻读、不可重复读
当前事务只能读取到其他事务已经提交的数据
#### 可重复读(Innodb默认隔离级别), 可能产生幻读
限制了读取数据的时候,不可以进行修改. 但读取范围数据时候, 可以插入数据
#### 串行化, 最高隔离级别, 多个事务串行执行

### 多事务竞争现象
1. 脏读: 2事务同时执行, 事务1可能读到事务2未提交的数据, 事务2可能回滚, 这就导致了事务1读到了最终不一定存在的数据
2. 不可重复读: 事务1在不同时刻读取同一行数据的结果不一样
3. 幻读: 事务1在做范围查询或修改时, 事务2在该范围插入1条数据并提交, 事务1就多查出1条数据或发现某条数据并未修改

### 为什么默认RR(可重复读)级别

## MVCC(基于多版本的并发控制)——RR实现原理
通过读取历史版本的数据, 降低并发事务冲突, 从而提高并发性能的一种机制
### 流程
1. 获取事务自己的版本号, 即事务ID
2. 获取Read View, 然后与Read View 中的事务版本号进行比较
4. 如果不符合Read View 可见性规则, 那就需要读undo log中历史快照
5. 最后返回符合规则数据

### read view可见性规则
#### 变量

<table class="table table-bordered table-striped">
	<caption>Read View</caption>
	<thead>
		<tr>
      <th>变量</th>
			<th>描述</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>m_ids</td>
			<td>当前系统中那些活跃(未提交)的读写事务id,为一个List</td>
		</tr>
    <tr>
			<td>max_limit_id</td>
			<td>生成Read View时,系统中应该分配给下一个事务的id值</td>
		</tr>
		<tr>
			<td>min_limit_id</td>
			<td>生成Read View时, 当前系统中活跃的读写事务中最小的事务id, 即m_ids中的最小值</td>
		</tr>
    <tr>
			<td>creator_trx_id</td>
			<td>创建当前Read View的事务id</td>
		</tr>
	</tbody>
</table>

#### 规则
1. 如果事务ID trx_id < min_limit_id, 表明生成该版本的事务在生成Read View前, 已经提交, 所以该版本可以被当前事务访问
2. 如果trx_id>= max_limit_id,表明生成该版本的事务在生成Read View后才生成,所以该版本不可以被当前事务访问
3. 如果min_limit_id <= trx_id < max_limit_id,需要分3种情况讨论
* 如果m_ids包含trx_id,则代表Read View生成时刻, 这个事务还未提交,但是如果数据的trx_id = creator_trx_id,表明数据是自己生成的, 因此可见
* 如果m_ids包含trx_id，并且trx_id ≠ creator_trx_id, 则Read View生成时,事务未提交并且不是自己生成的,所以当前事务也看不见
* 如果m_ids不包含trx_id, 则说明你这个事务在Read View生成之前就已经提交了, 当前事务能看见

## LBCC(基于锁的并发控制)

##  高并发下如何保证安全的修改同一行数据
### 悲观锁
当前线程修改数据时, 其他线程阻塞, 即本次事务提交之前, 别的线程都无法修改记录
### 乐观锁
有线程修改数据时, 如果其他线程没有修改过, 就修改成功, 否则失败. 乐观锁一般使用版本号或CAS算法实现

### select ... for update 加锁
查询条件使用主键/索引, 则会加行锁, 若没有使用加表锁

## Mysql中innodb的锁
### 根据加锁机制
1. 悲观
2. 乐观

### 根据锁粒度
1. 表锁: 开销小, 加锁快, 锁粒度大, 发生冲突概率高, 并发度低, 不会死锁
2. 行锁: 开销大, 加锁慢, 锁粒度小, 发生冲突概率低, 并发度高, 会死锁
3. 页锁: 开销介于表锁和行锁之间, 锁粒度介于表锁和行锁之间, 并发度一般, 会死锁

### 根据锁模式
#### 记录锁
1. 记录锁即行锁, 记录锁都是加载索引上的, 它会阻塞其他事务对该行记录的修改
#### 间隙锁
1. 间隙锁是加载两个索引之间,或第一个索引之前, 或最后一个索引之后的锁, 锁住的是一个区间
#### 临键锁
1. 记录锁和间隙锁的组合, 即加在某条记录及其之前的间隙上的锁, 是一个左开右闭的区间
#### 意向锁: 不与行锁冲突的表锁. 在未来事务可能要加S或X锁时, 先提前声明一个意向
1. 原因: 事务1持有某行X锁, 并未提交. 事务2获取同一表的S锁时, 因为S与X互斥, 要保证没有其他事务持有该表的排他锁,也没有其他食物持有表中任一行的排他锁, 遍历每一行进行检查显然效率非常低, 因此引入意向锁
2. 意向共享锁(IS)
* 当事务需要给某些记录加S锁时, 需要先在表上加IS锁(select...lock in share mode)
3. 意向排他锁(IX)
* 当事务需要给某些记录加X锁时, 需要先在表上加IX锁(select...for update)

#### 插入意向锁
1. 插入意向锁是插入一行记录操作之前设置的一种间隙锁. 多个事务,在同一个索引,同一个范围区间插入记录时,如果插入的位置不冲突，不会阻塞彼

#### 自增锁
1. 自增锁特殊的表锁, 针对AUTO_INCREMENT类型的列, 如果表中新增数据时就会持有自增锁.
2. innodb_autoinc_lock_mode=0
3. innodb_autoinc_lock_mode=1
4. innodb_autoinc_lock_mode=2

### 根据兼容性
1. 共享锁(S)
* 在事务读取一条记录时, 需要先获取该记录的S锁
* 事务1持有R行的S锁, 事务2请求访问该行时, 请求S锁会被立即允许, 事务1和事务2都持有R行S锁; 请求X锁时不被立即允许, 此操作阻塞
2. 排他锁(X)
* 在事务改动一条记录时, 需要先获取该记录的X锁
* 事务1持有R行的X锁, 事务2请求R行的X, S锁都不会被立即允许,事务2必须等待事务1释放X锁(X锁与其他任何锁都不兼容)
3. S,X锁也可以加在表上, 效果行锁相同

## 事务四大特性
事务即工作的原子单元, 可以进行提交和回滚, 保证1条或多条SQL语句作为1个原子操作, 要么全部成功要么全部不成功
1. 原子性: 事务作为一个整体执行, 要么全部执行要么全部不执行
* 使用undo log实现, 执行事务时, 将修改前的数据保存到undo log, 一旦出错, 从undo log读取出来进行反操作
2. 一致性: 事务前后数据的完整性保持一致. 
* 更多是从业务层面保证, mysql也提供了一些机制
3. 隔离性: 多个事务并发访问时, 事物之间相互隔离,互不影响.
* 使用锁和MVCC实现
4. 持久性： 保证数据不丢失, 也即事务一旦提交, 数据的改变是永久性的, 即使出现宕机等故障, 也不受影响
* 使用redo log实现. 理论上事务提交后数据直接持久化到磁盘即可, 但磁盘IO效率低, 因此innodb设计了缓冲区, 将数据变更先更新到内存缓冲区, 等合适时机再持久化到磁盘. 如果在持久化过程中发生宕机等问题, 就会导致数据丢失, 因此设计redo log文件, 当数据变更时处理修改缓冲区内的数据外, 还会把数据追加到redo log里


## in和exists区别
两者执行顺序不同, in先执行子查询, exists则先执行主查询. 在选择in或exists时遵循小表驱动大表的原则即可

## 数据库自增主键可能遇到什么问题
1. 自增主键会产生表锁, 产生并发问题
2. 自增主键可能用完
3. 在分库分表下, 可能出现主键重复等问题

## Mysql主从延迟如何解决
### 主从复制原理
  <img src= "/assets/files/mysql主从复制.jpg" alt="加载错误" title="mysql主从复制原理"/>

1. 主库更新事件写入binlog
2. 从库发起连接到主库
3. 主库创建binlog dump thread 将binlog内容发送到从库
4. 从库创建IO线程, 读取主库传来的binlog内容并写入relay log
5. 从库创建SQL线程, 将relay log中的内容更新到从库

### binlog录入格式
1. statement: 记录SQL原文, 不需要记录每一行的变化, 减少了日志量, 节约了IO. SQL执行有上下文, 因此还保存上下文相关信息, 可能导致数据不一致
2. row: 不记录SQL语句上下文相关信息, 仅保存哪条记录被修改, 日志量大
3. mixed: 普通操作使用statement, 无法使用statement时使用row

### 主从延迟原因
主库大量并发更新操作, 而从库只有一个读取binlog的线程, 当从库中某个SQL执行时间太长或者执行时锁表, 导致主库大量SQL积压, 未被同步到从库
### 解决办法
1. 增加服务器, 分散读压力
2. 把一台服务器当作数据备份, 不提供查询, 负载自然降低, 执行relay log效果就变高
3. 使用更好的设备作从库
4. 主库负责更新操作, 安全性要求相对从库较高, 可以修改sync_binlog=1, innodb_flush_log_at_trx_commit=1等配置

## 数据库连接池
1. 是一种池化技术, 目的是为了资源复用, 以避免资源重复创建销毁带来的额外开销. 应用每次向数据库发起的CRUD操作都会创建连接, 在数据访问量较大时, 频繁创建连接会带来较大的性能开销
2. 连接池核心思想就是在应用启动时初始化一部分连接保存到连接池里, 应用需要使用连接时, 直接从池里获取即可, 避免每次创建和释放带来的开销
3. 除了资源复用外, 还带来了更快的响应速度, 统一的连接管理

## SQL语句执行步骤
1. 检查语句是否有权限
2. 没有则直接返回错误
3. 有则先检查缓存
4. 没有缓存则, 分析器会分析SQL语句, 检查是否有语法错误等
5. 优化器会确定执行方案
6. 执行器调用存储引擎接口, 返回执行结果

### SQL生命周期
1. 服务器与数据库建立连接
2. 数据库进程拿到请求的sql
3. 解析并生成执行计划, 执行
4. 读取数据到内存, 并进行逻辑处理
5. 通过步骤1的连接, 发送结果到客户端
6. 关闭连接, 释放资源

### 一条SQL执行顺序
from -> on -> where -> group by -> having -> select -> DISTINCT -> order by -> limit

## mysql基础架构
  <img src= "/assets/files/mysql基础架构图.jpg" alt="加载错误" title="mysql基础架构图"/>

1. 第一层: 负责连接处理, 授权认证、安全等
2. 第二层: 负责编译优化SQL
3. 第三层: 存储引擎

## count(*)、count(1)、count(列名)区别
count(*)和count(1)直接查询符合条件的数据表的行数, count(列名)则查询符合条件的列值不为NULL的行数
### count(*)的优化
1. Innodb
* 因为支持事务和行锁, count(*)不可避免地要扫表
* 而count(*)只统计行数, 不关心具体值, 因此在扫表时选择一个最小的非主键索引来扫表(非主键索引的叶子节点只保存该行记录的主键值)
* 前提是没有where或group by等条件
2. MyISAM
* MyISAM把表的总行数单独记录, count(*)时直接返回该记录, 前提是没有where条件.
* 因为只支持表锁, 不会有并发修改行

## SQL约束有哪些
1. NOT NULL: 约束字段不能为NULL
2. UNIQUE: 约束字段唯一性, 一个表允许多个unique约束
3. PRIMARY KEY: 约束字段唯一, 不可重复, 一个表只有一个
4. FOREIGN KEY: 
5. CHECK

## drop、truncate、delete区别
1. drop: DDL操作, 删表, 不可回滚, 速度最快
2. truncate: DDL操作, 删除表全部数据, 不可回滚, 速度快
3. delete: DML操作, 删除表中全部或部分数据, 可回滚, 速度慢(逐行删除)

## CPU飙高处理
### 原因
1. CPU上下文切换过多
对于CPU来说,同一时刻下每个CPU核心只能运行一个线程,如果有多个线程要执行，CPU只能通过上下文切换的方式来执行不同的线程. 上下文切换需要做两个事情:
* 保存运行线程的执行状态
* 让处于等待的线程执行
这两个过程需要CPU执行内核相关指令实现状态保存，如果较多的上下文切换会占据大量CPU资源，从而使得CPU无法去执行用户进程中的指令，导致响应速度下降。在Java 中，文件IO、网络IO、锁等待、线程阻塞等操作都会造成线程阻塞从而触发上下文切换
2. CPU资源过度消耗
* 创建了大量线程
* 有线程一直占用CPU